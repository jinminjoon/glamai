{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mycelebs_95/Projects/glamai_data/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import pymysql\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from database.conn import AccessDatabase\n",
    "from crawling.crawler import get_url, json_iterator, get_headers\n",
    "today = datetime.today().strftime('%y%m%d')\n",
    "\n",
    "db_glamai = AccessDatabase('glamai')\n",
    "db_jangho = AccessDatabase('jangho')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1st) Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.refinement import Refinement\n",
    "products = Refinement().update_refinement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2nd) Products By Subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.product_keyword import ProductKeyword\n",
    "upload_df = ProductKeyword().update_product_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3rd) Update Vertical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.vertical_data import VerticalData\n",
    "VerticalData().update_vertical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4th) Update Best & New & Vegan & Organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.best_new import UpdateBestSellerNew\n",
    "from sephora_product.keywords import SephoraVeganOrganic\n",
    "UpdateBestSellerNew().update_best_new()\n",
    "SephoraVeganOrganic().update_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5th) Review Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.review_date import ReviewDate\n",
    "new_product_list, data = ReviewDate().update_review_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6th) Insert product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.insert_product_info import update_product_info\n",
    "result = update_product_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7th) All product update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.all_product_update import update_all_product\n",
    "data = update_all_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Search Keywords Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.search_keyword import update_search_keywords, db_distinction\n",
    "total_df = update_search_keywords()\n",
    "db_distinction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Review Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1st) Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backup table\n",
    "# table = 'sephora_txt_data_re'\n",
    "# db_glamai._backup(table_name=table, keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update review data\n",
    "from sephora_review.review_data import ReviewData\n",
    "txt_data, error = ReviewData()._crawling(backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check crawling result\n",
    "\n",
    "columns = ['product_code', 'product_id', 'rating', 'skin_type', 'eye_color', 'skin_concerns', 'hair_color', 'skin_tone', 'age', 'title', 'txt_data', 'positive_count', 'write_time', 'regist_date']\n",
    "rev_df = pd.DataFrame(txt_data, columns=columns)\n",
    "\n",
    "error_df = pd.DataFrame(error, columns=['product_code', 'product_url', 'note'])\n",
    "error_df_cnt = error_df.groupby('note').count()\n",
    "\n",
    "rev_df.groupby('product_code').count()\n",
    "\n",
    "print(\\\n",
    "    f\"product counts: {len(rev_df.product_code.unique())}\\n\\\n",
    "    product review counts: {len(rev_df)}\\n\\\n",
    "    reviews that already exist: {error_df_cnt.iloc[0, 0]}\\n\\\n",
    "    review does not exist: {error_df_cnt.iloc[1, 0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2nd) Review Date Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_review.review_data import ReviewDate\n",
    "result = ReviewDate().update_review_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3rd) Duplicate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/* replace */ \n",
    "UPDATE sephora_txt_data_re SET txt_data = REPLACE(txt_data, '.Not impressed.', '.') WHERE BINARY(txt_data) LIKE '%Not impressed.';\n",
    "\n",
    "/* check duplicated */\n",
    "select product_code, txt_data, write_time, like_count, count(*) as cnt\n",
    "from sephora_txt_data_re\n",
    "group by product_code, txt_data, write_time\n",
    "having cnt > 1;\n",
    "\n",
    "/* dedup */\n",
    "\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2 \n",
    "where \n",
    "t1.product_code=t2.product_code and \n",
    "t1.txt_data = t2.txt_data and \n",
    "t1.write_time =t2.write_time and\n",
    "t1.like_count < t2.like_count;\n",
    "\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2\n",
    "where \n",
    "t1.product_code = t2.product_code and \n",
    "t1.txt_data = t2.txt_data and\n",
    "t1.write_time = t2.write_time and\n",
    "t1.like_count = t2.like_count and\n",
    "t1.pk < t2.pk;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_query = \"UPDATE sephora_txt_data_re SET txt_data = REPLACE(txt_data, '.Not impressed.', '.') WHERE BINARY(txt_data) LIKE '%Not impressed.';\"\n",
    "dedup_query_1 = '''\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2 \n",
    "where \n",
    "t1.product_code=t2.product_code and \n",
    "t1.txt_data = t2.txt_data and \n",
    "t1.write_time =t2.write_time and\n",
    "t1.like_count < t2.like_count;\n",
    "'''\n",
    "dedup_query_2 = '''\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2\n",
    "where \n",
    "t1.product_code = t2.product_code and \n",
    "t1.txt_data = t2.txt_data and\n",
    "t1.write_time = t2.write_time and\n",
    "t1.like_count = t2.like_count and\n",
    "t1.pk < t2.pk;'''\n",
    "\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(replace_query)\n",
    "conn.commit()\n",
    "curs.execute(dedup_query_1)\n",
    "conn.commit()\n",
    "curs.execute(dedup_query_2)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check query\n",
    "\n",
    "query = '''\n",
    "select product_code, txt_data, write_time, like_count, count(*) as cnt\n",
    "from sephora_txt_data_re\n",
    "group by product_code, txt_data, write_time\n",
    "having cnt > 1;'''\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "if len(data) == 0:\n",
    "    print('Complete dedup!')\n",
    "else:\n",
    "    print('Dedup Failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Status \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status\n",
    "\n",
    "verticals = ['treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers', 'face_base', 'eye', 'lip_color', 'moisturizers', 'cheek']\n",
    "df_list = []\n",
    "for vertical in verticals:\n",
    "    query = f'select is_use, count(*) as count, \"{vertical}\" as vertical from `sephora_{vertical}_data_status` group by is_use;'\n",
    "    conn, curs = db_glamai._connect()\n",
    "    curs.execute(query)\n",
    "    data = curs.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df, '\\n\\n')\n",
    "    df_list.append(df)\n",
    "\n",
    "curs.close()\n",
    "conn.close()    \n",
    "status_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bak_date = input(\"Enter the date [ ex) `221203` ] :  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check product counts\n",
    "verticals = ['treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers', 'face_base', 'eye', 'lip_color', 'moisturizers', 'cheek']\n",
    "conn, curs = db_glamai._connect()\n",
    "datas = []\n",
    "current, paste = 0, 0\n",
    "for vertical in verticals:\n",
    "    query = f'''\\\n",
    "    select 'sephora_{vertical}_data_status' as tbl, count(*) as cnt from sephora_{vertical}_data_status union\\\n",
    "    select 'sephora_{vertical}_data_status_bak_{bak_date}', count(*) as cnt from sephora_{vertical}_data_status_bak_{bak_date};'''\n",
    "    curs.execute(query)\n",
    "    data = curs.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df, '\\n\\n')\n",
    "    datas += data\n",
    "    current += df.iloc[0, 1]\n",
    "    paste += df.iloc[1, 1]\n",
    "    \n",
    "curs.close()\n",
    "conn.close()    \n",
    "\n",
    "df = pd.DataFrame(datas)\n",
    "print(f' - Current: {current}\\n - Paste: {paste}\\n - Increasement: {current - paste}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check product counts where is_use=1\n",
    "verticals = ['treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers', 'face_base', 'eye', 'lip_color', 'moisturizers', 'cheek']\n",
    "conn, curs = db_glamai._connect()\n",
    "datas = []\n",
    "current, paste = 0, 0\n",
    "for vertical in verticals:\n",
    "    query = f'''\\\n",
    "    select 'sephora_{vertical}_data_status' as tbl, count(*) as cnt from sephora_{vertical}_data_status where is_use=1 union\\\n",
    "    select 'sephora_{vertical}_data_status_bak_{bak_date}', count(*) as cnt from sephora_{vertical}_data_status_bak_{bak_date} where is_use=1;'''\n",
    "    curs.execute(query)\n",
    "    data = curs.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df, '\\n\\n')\n",
    "    datas += data\n",
    "    current += df.iloc[0, 1]\n",
    "    paste += df.iloc[1, 1]\n",
    "    \n",
    "curs.close()\n",
    "conn.close()    \n",
    "\n",
    "df = pd.DataFrame(datas)\n",
    "print(f' - Current: {current}\\n - Paste: {paste}\\n - Change: {current - paste}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_update.sales import update_sephora_sale\n",
    "\n",
    "price_data_dict = {}\n",
    "verticals = ['treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers', 'face_base', 'eye', 'lip_color', 'moisturizers', 'cheek']\n",
    "for vertical in tqdm(verticals):\n",
    "    price_data = update_sephora_sale(vertical)\n",
    "    price_data_dict[vertical] = price_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Affiliate price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' glamai.affiliate_price dedup & dup check\n",
    "\n",
    "/* dedup */\n",
    "delete \n",
    "\tt1 \n",
    "from \n",
    "\tglamai.affiliate_price t1, glamai.affiliate_price t2\n",
    "where \n",
    "\tt1.product_code = t2.product_code and \n",
    "\tt1.item_no = t2.item_no and\n",
    "\tt1.affiliate_type = t2.affiliate_type and\n",
    "\tt1.update_date < t2.update_date;\n",
    "\n",
    "/* dup check */\t\n",
    "select product_code, item_no, affiliate_type, count(*) cnt from glamai.affiliate_price group by product_code, item_no, affiliate_type having cnt > 1;\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Amazon update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affiliate.amazon import get_data_amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_date = input(\"Enter the date [ ex) `221203` ] :  \")\n",
    "\n",
    "tbl = f'affiliate_price_update_amazon_{_date}'\n",
    "upload_df = db_jangho.get_tbl(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df.groupby('is_use').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df[upload_df.is_use==1].groupby('is_sale').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check url \n",
    "_data = []\n",
    "for url in upload_df[(upload_df.is_use==-1) | (upload_df.is_use==2)].affiliate_url:\n",
    "    # wd = get_url(url, window=True, image=True)\n",
    "    # _data.append(get_data_amazon(url))\n",
    "    _data.append(get_data_amazon(url, window=True, image=True))\n",
    "_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "update glamai.affiliate_price as a\n",
    "join jangho.affiliate_price_update_amazon_{_date} as b \n",
    "on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "set a.price = b.price, a.sale_price = b.sale_price, a.is_sale = b.is_sale, a.is_use = b.is_use, a.regist_date = b.regist_date, a.update_date = b.update_date\n",
    "where b.is_use!=-1;'''\n",
    "\n",
    "conn, curs = db_jangho._connect()\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check query\n",
    "query = 'select * from affiliate_price where is_use=1 and is_sale=0 and sale_price=0;'\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "if len(data) == 0:\n",
    "    print(\"Complete amazon status data!\")\n",
    "else:\n",
    "    print(\"Error: Check status!\")\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Ulta update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_date = input(\"Enter the date [ ex) `221203` ] :  \")\n",
    "\n",
    "tbl = f'affiliate_price_update_ulta_{_date}'\n",
    "upload_df = db_jangho.get_tbl(tbl)\n",
    "upload_df.groupby('is_use').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df[upload_df.is_use==1].groupby('is_sale').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "update glamai.affiliate_price as a\n",
    "join jangho.affiliate_price_update_ulta_{_date} as b \n",
    "on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "set a.price = b.price, a.sale_price = b.sale_price, a.is_sale = b.is_sale, a.is_use = b.is_use, a.regist_date = b.regist_date, a.update_date = b.update_date\n",
    "where b.is_use!=-1;'''\n",
    "\n",
    "conn, curs = db_jangho._connect()\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check query\n",
    "\n",
    "query = 'select * from affiliate_price where is_use=1 and is_sale=0 and sale_price=0;'\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "if len(data) == 0:\n",
    "    print(\"Complete update ulta sale!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Walmart update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from affiliate._preprocess import preprocess_titles, dup_check, subtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Glamai Tables\n",
    "- ds > jangho > `glamai_data`\n",
    "- ds > jangho > `glamai_detail_data`\n",
    "'''\n",
    "\n",
    "columns = ['product_code', 'item_no', 'product_name', 'brand', 'main_vertical', 'size', 'is_use']\n",
    "glamai_data = db_jangho.get_tbl('glamai_data', columns)\n",
    "columns = ['product_code', 'item_no', 'color', 'is_use']\n",
    "glamai_detail = db_jangho.get_tbl('glamai_detail_data', columns)\n",
    "\n",
    "glamai_df_0 = glamai_data.merge(glamai_detail.loc[:, ['product_code', 'item_no', 'color']], on=['product_code', 'item_no'], how='left')\n",
    "glamai_df_1 = glamai_data.loc[:, ['product_code', 'product_name', 'brand', 'main_vertical']].merge(glamai_detail.loc[:, ['product_code', 'item_no', 'color', 'is_use']], on=['product_code'], how='left')\n",
    "glamai_df = pd.concat([glamai_df_0, glamai_df_1]).drop_duplicates(subset=['product_code', 'item_no'], ignore_index=True)\n",
    "\n",
    "glamai_df.loc[glamai_df['color'].str.strip()=='', 'color'] = None\n",
    "glamai_df.loc[glamai_df['size']=='', 'size'] = None\n",
    "\n",
    "'''Walmart Tables\n",
    "walmart_item_data_{_date}\n",
    "walmart_variant_data_{_date}\n",
    "walmart_variant_data_price_{_date}\n",
    "'''\n",
    "\n",
    "# /** Enter the Date **/\n",
    "_date = '221122'\n",
    "_walmart_df = db_jangho.get_tbl(f'walmart_item_data_{_date}')\n",
    "_walmart_df.loc[:, 'url'] = 'https://www.walmart.com/' + _walmart_df.loc[:, 'canonicalUrl']\n",
    "\n",
    "subset = ['usItemId']\n",
    "walmart_df_dedup = _walmart_df.drop_duplicates(subset=subset, keep='first', ignore_index=True)\n",
    "col = ['pk', 'usItemId', 'brand', 'product_name']\n",
    "walmart_df = walmart_df_dedup.loc[:, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df_0 = preprocess_titles(glamai_df)\n",
    "preprocessed_df_1 = preprocess_titles(walmart_df)\n",
    "preprocessed_df_0 = preprocessed_df_0[(preprocessed_df_0.brand.notnull()) & (preprocessed_df_0.preprocessed.notnull())].reset_index(drop=True)\n",
    "preprocessed_df_1 = preprocessed_df_1[(preprocessed_df_1.brand.notnull()) & (preprocessed_df_1.preprocessed.notnull())].reset_index(drop=True)\n",
    "\n",
    "df_list = []\n",
    "for idx in tqdm(preprocessed_df_0.index):\n",
    "    product_code = preprocessed_df_0.loc[idx, 'product_code']\n",
    "    item_no = preprocessed_df_0.loc[idx, 'item_no']\n",
    "    \n",
    "    \n",
    "    color = preprocessed_df_0.loc[idx, 'color']\n",
    "    size = preprocessed_df_0.loc[idx, 'size']\n",
    "    # color_category = preprocessed_df_0.loc[idx, 'color_category']\n",
    "    title = preprocessed_df_0.loc[idx, 'preprocessed'].lower().replace(' ', '')\n",
    "    brand = preprocessed_df_0.loc[idx, 'brand'].lower().replace(' ', '')\n",
    "    \n",
    "    # 브랜드, 타이틀 모두 일치하는 개체 찾기\n",
    "    brand_mapped = preprocessed_df_1.brand.str.lower().str.replace(' ', '').str.fullmatch(brand)\n",
    "    title_mapped = preprocessed_df_1.preprocessed.str.replace(' ', '').str.fullmatch(title)\n",
    "    mapped_data = preprocessed_df_1[brand_mapped & title_mapped].reset_index(drop=True)\n",
    "    \n",
    "    if mapped_data.empty:\n",
    "        pass\n",
    "    else:    \n",
    "        mapped_data.loc[:, 'product_code'] = product_code\n",
    "        mapped_data.loc[:, 'item_no'] = item_no\n",
    "        mapped_data.loc[:, 'color'] = color\n",
    "        mapped_data.loc[:, 'size'] = size\n",
    "        # mapped_data.loc[:, 'color_category'] = color_category\n",
    "        df_list.append(mapped_data)\n",
    "\n",
    "mapped_df = pd.concat(df_list, ignore_index=True)\n",
    "options_df = db_jangho.get_tbl(f'walmart_variant_data_price_{_date}')\n",
    "for idx in options_df.index:\n",
    "    opts = ast.literal_eval(options_df.loc[idx, 'option'])\n",
    "    _opts = []\n",
    "    i = 1\n",
    "    for opt in opts:\n",
    "        # opt = opt.replace('size-', '').replace('actual_color-', '').strip()\n",
    "        # options_df.loc[idx, f'option_{i}'] = str(opt)\n",
    "        # i += 1\n",
    "        \n",
    "        if opt[0:12] == 'actual_color':\n",
    "            color = opt.replace('actual_color-', '').strip()\n",
    "            options_df.loc[idx, 'walmart_color'] = color\n",
    "        elif opt[0:4] == 'size':\n",
    "            size = opt.replace('size-', '').strip()\n",
    "            options_df.loc[idx, 'walmart_size'] = size\n",
    "        else:\n",
    "            options_df.loc[idx, 'another_option'] = opt\n",
    "            \n",
    "options_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대표상품 중 옵션 존재 개체 join\n",
    "# opt_0 = mapped_df.merge(options_df.loc[:, ['usItemId', 'productId', 'option_1', 'option_2']], on='usItemId', how='left')\n",
    "opt_0 = mapped_df.merge(options_df.loc[:, ['usItemId', 'productId', 'walmart_color', 'walmart_size', 'another_option']], on='usItemId', how='left')\n",
    "\n",
    "# 매핑 상품에 옵션 부여\n",
    "pks = mapped_df.pk.unique() # 매핑 완료 개체 (대표상품)\n",
    "ids = opt_0[opt_0.productId.notnull()].usItemId.unique() # 대표상품 중 옵션 존재 usItemId\n",
    "# col = ['pk', 'productId', 'usItemId', 'product_name', 'option_1', 'option_2']\n",
    "col = ['pk', 'productId', 'usItemId', 'product_name', 'walmart_color', 'walmart_size', 'another_option']\n",
    "_opt_1 = options_df.loc[(options_df.pk.isin(pks)) & (options_df.usItemId.isin(ids)==False), col]\n",
    "\n",
    "col = ['pk', 'product_code', 'item_no', 'brand', 'color', 'size']\n",
    "_mapped_df = mapped_df.loc[:, col]\n",
    "opt_1 = _opt_1.merge(_mapped_df, on='pk', how='left')\n",
    "\n",
    "# concat\n",
    "mapped_opt_df = pd.concat([opt_0, opt_1]).sort_values(by=['pk', 'usItemId'], ignore_index=True)\n",
    "\n",
    "# convert np.nan to None\n",
    "mapped_opt_df = mapped_opt_df.where(pd.notnull(mapped_opt_df), None)\n",
    "\n",
    "mapped_opt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['option_1', 'option_2', 'volume_oz', 'volume_ml', 'volume_kg']\n",
    "cols = ['walmart_color', 'walmart_size', 'another_option', 'volume_oz', 'volume_ml', 'volume_kg']\n",
    "opts = ['color', 'size']\n",
    "# opts = ['color']\n",
    "for idx in mapped_opt_df.index:\n",
    "    if mapped_opt_df.loc[idx, cols+opts].isnull().values.tolist().count(True) == len(opts) + len(cols):\n",
    "        # 옵션 자체가 존재하지 않음\n",
    "        status = -1       \n",
    "        attrs = None\n",
    "    else:\n",
    "        attrs = []\n",
    "        for opt in opts:    \n",
    "            opt = mapped_opt_df.loc[idx, opt]\n",
    "            if opt is None:\n",
    "                pass\n",
    "            else:\n",
    "                opt = opt.lower().replace(' ', '')\n",
    "                col_cnt = 0\n",
    "                for col in cols:\n",
    "                    attr = mapped_opt_df.loc[idx, col]\n",
    "                    if attr is None:\n",
    "                        pass\n",
    "                    else:    \n",
    "                        attr = attr.lower().replace(' ', '')\n",
    "                        if attr in opt:\n",
    "                            attrs.append(attr)\n",
    "        if len(attrs) == 0:\n",
    "            # 옵션은 존재하지만 일치하지 않음\n",
    "            status = 0\n",
    "            attrs = None\n",
    "        else:\n",
    "            # 옵션 일치\n",
    "            status = 1\n",
    "            attrs = str(list(set(attrs))) \n",
    "    \n",
    "    mapped_opt_df.loc[idx, 'attributes'] = attrs\n",
    "    mapped_opt_df.loc[idx, 'mapped_status'] = status\n",
    "\n",
    "# group by mapped_status count\n",
    "mapped_opt_df.groupby('mapped_status').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['product_code', 'item_no', 'brand', 'pk', 'usItemId', 'productId', 'attributes']\n",
    "mapped_df_comp = mapped_opt_df.loc[mapped_opt_df.mapped_status==1, columns].sort_values(by=['product_code', 'item_no'], ignore_index=True)\n",
    "print(f'- Glamai data: {len(glamai_df)}\\n- Walmart data: {len(walmart_df)}\\n- Mapping data: {len(mapped_df_comp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Table\n",
    "# db_jangho.engine_upload(mapped_opt_df, f'sephora_to_walmart_mapped_test_{_date}', if_exists_option='replace')\n",
    "\n",
    "# Table Upload: ds > jangho > sephora_to_walmart_mapped_{_date}\n",
    "db_jangho.engine_upload(mapped_opt_df, f'sephora_to_walmart_mapped_{_date}', if_exists_option='replace')\n",
    "\n",
    "# mapped_opt_df = db_jangho.get_tbl(f'sephora_to_walmart_mapped_{_date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maaping: sephora to walmart\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = db_jangho.get_tbl(f'walmart_item_data_{_date}')\n",
    "v_p_df = db_jangho.get_tbl(f'walmart_variant_data_price_{_date}')\n",
    "map_df = db_jangho.get_tbl(f'sephora_to_walmart_mapped_{_date}')\n",
    "cols = ['product_code', 'item_no', 'usItemId', 'mapped_status']\n",
    "_map_df = map_df.loc[:, cols]\n",
    "\n",
    "cols = ['usItemId', 'canonicalUrl', 'price', 'sale_price', 'availabilityStatus']\n",
    "_item_df = item_df.loc[:, cols]\n",
    "_v_p_df = v_p_df.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge: price data\n",
    "mer_df_0 = _map_df.merge(_item_df, on='usItemId', how='inner')\n",
    "mer_df_1 = _map_df.merge(_v_p_df, on='usItemId', how='inner')\n",
    "\n",
    "mer_df = pd.concat([mer_df_0, mer_df_1], ignore_index=True)\n",
    "subset = ['product_code', 'item_no', 'usItemId']\n",
    "dedup_df = mer_df.drop_duplicates(subset=subset, keep='last', ignore_index=True)\n",
    "\n",
    "# affiliate data\n",
    "dedup_df.loc[:, 'affiliate_type'] = 'walmart'\n",
    "dedup_df.loc[:, 'affiliate_url'] = 'https://www.walmart.com' + dedup_df['canonicalUrl']\n",
    "dedup_df.loc[:, 'affiliate_image'] = 'https://alls3.glamai.com/images/affiliate/walmart.jpg'\n",
    "# stock status check (is_use)\n",
    "dedup_df.loc[(dedup_df['availabilityStatus']=='In stock') | (dedup_df['availabilityStatus']=='IN_STOCK'), 'is_use'] = True\n",
    "dedup_df.loc[(dedup_df['availabilityStatus']!='In stock') & (dedup_df['availabilityStatus']!='IN_STOCK'), 'is_use'] = False\n",
    "\n",
    "# sale status check (is_sale)\n",
    "dedup_df.loc[dedup_df['price']>dedup_df['sale_price'], 'is_sale'] = True\n",
    "dedup_df.loc[dedup_df['price']==dedup_df['sale_price'], 'is_sale'] = False\n",
    "\n",
    "dedup_df.loc[dedup_df['sale_price']==0, 'is_sale'] = False\n",
    "dedup_df.loc[dedup_df['sale_price']==0, 'is_use'] = False\n",
    "columns = ['product_code', 'item_no', 'affiliate_type', 'affiliate_url', 'affiliate_image', 'usItemId', 'price', 'sale_price', 'is_sale', 'is_use']\n",
    "upload_df = dedup_df.loc[dedup_df.mapped_status==1, columns].sort_values(by=['product_code', 'item_no'], ignore_index=True)\n",
    "upload_df.loc[:, 'regist_date'] = pd.Timestamp(datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "upload_df.loc[:, 'update_date'] = pd.Timestamp(datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "upload_df.info()\n",
    "upload_df[upload_df.is_use==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "월마트 내부 중복 체크 \n",
    " - dedup = 1(True): 대표상품 (가격 낮은 상품)\n",
    " - dedup = 0(False): 종속상품 (가격 높은 상품 or is_use = 0(False))\n",
    "\"\"\"\n",
    "_upload_df = upload_df[upload_df.is_use].sort_values(by='sale_price', ignore_index=True)\n",
    "upload_df_ = upload_df[upload_df.is_use==False]\n",
    "\n",
    "subset = ['product_code', 'item_no']\n",
    "dedup_df = _upload_df.drop_duplicates(subset=subset, keep='first', ignore_index=True)\n",
    "dup_df = dup_check(df=_upload_df, subset=subset, keep='first', sorting=True)\n",
    "\n",
    "dedup_df.loc[:, 'dedup'] = True\n",
    "if not upload_df_.empty:\n",
    "    upload_df_ = upload_df_.reset_index(drop=True)\n",
    "    upload_df_.loc[:, 'dedup'] = False # is_use=0(False) 이면 중복으로 간주 -> 서비스 테이블에 insert 안 되게 하기 위함\n",
    "dup_df.loc[:, 'dedup'] = False\n",
    "concat_df = pd.concat([dedup_df, upload_df_, dup_df]).sort_values(by=subset, ignore_index=True)\n",
    "\n",
    "concat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_df.groupby('is_use').count()\n",
    "concat_df.groupby('dedup').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Upload: ds > jangho > sephora_to_walmart_mapped\n",
    "db_jangho.create_table(upload_df=concat_df, table_name='sephora_to_walmart_mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "update glamai.affiliate_price as a\n",
    "join jangho.sephora_to_walmart_mapped as b \n",
    "on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "set a.price = b.price, a.sale_price = b.sale_price, a.is_sale = b.is_sale, a.is_use = b.is_use, a.update_date = b.update_date\n",
    "where b.dedup=1;'''\n",
    "\n",
    "data = db_jangho._execute(query)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT product_code, item_no\n",
    "FROM affiliate_price as a\n",
    "WHERE a.is_use=1 and a.affiliate_type='walmart';\n",
    "\"\"\"\n",
    "\n",
    "data = db_glamai._execute(query)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_df = concat_df.loc[concat_df.dedup, ['product_code', 'item_no', 'affiliate_type', 'affiliate_url', 'affiliate_image', 'price', 'sale_price', 'is_sale', 'is_use', 'regist_date', 'update_date']]\n",
    "\n",
    "subset=['product_code', 'item_no']\n",
    "new_df = subtractor(dedup_df, df, subset)\n",
    "print(f\"\\n\\nNew product counts: {len(new_df)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affi_tbl = \"affiliate_price\"\n",
    "\n",
    "# Table bakcup: ds > glamai > affiliate_price_bak_{_date}\n",
    "db_glamai._backup(table_name=affi_tbl, keep=True)\n",
    "\n",
    "# Table upload: ds > glamai > affiliate_price\n",
    "db_glamai.engine_upload(upload_df=new_df, table_name=affi_tbl, if_exists_option='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glamai.affiliate_price dedup & dup check\n",
    "\n",
    "# /* dedup */\n",
    "\n",
    "dedup_query = f\"\"\"\n",
    "delete \n",
    "\tt1 \n",
    "from \n",
    "\tglamai.affiliate_price t1, glamai.affiliate_price t2\n",
    "where \n",
    "\tt1.product_code = t2.product_code and \n",
    "\tt1.item_no = t2.item_no and\n",
    "\tt1.affiliate_type = t2.affiliate_type and\n",
    "\tt1.update_date < t2.update_date;\"\"\"\n",
    "\n",
    "# /* dup check */\t\n",
    "\n",
    "dup_check_query = f\"\"\"\n",
    "select product_code, item_no, affiliate_type, count(*) cnt from glamai.affiliate_price group by product_code, item_no, affiliate_type having cnt > 1;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_glamai._execute(dup_check_query)\n",
    "df = pd.DataFrame(data)\n",
    "if df.empty:\n",
    "    print(\"중복 제거 완료.\")\n",
    "else:\n",
    "    print(\"중복인 행이 존재합니다. 중복제거 진행합니다.\")\n",
    "    data = db_glamai._execute(dedup_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e13581618c17731e2f387e6cdae1396e442743c6bb2b5fd11d35971355b684"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
