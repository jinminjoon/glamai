{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeonseosla/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import pymysql\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):\n",
    "#     root = sys._MEIPASS\n",
    "# else:\n",
    "#     cur_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "#     root = os.path.abspath(os.path.join(cur_dir, os.pardir, os.pardir))\n",
    "#     src  = os.path.join(root, 'src')\n",
    "#     sys.path.append(src)\n",
    "\n",
    "from database.access import AccessDatabase\n",
    "from crawling.crawler import get_url, json_iterator\n",
    "today = datetime.today().strftime('%y%m%d')\n",
    "db_glamai = AccessDatabase('glamai')\n",
    "db_jangho = AccessDatabase('jangho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1st) Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.refinement import Refinement\n",
    "products = Refinement().update_refinement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2nd) Products By Subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.product_keyword import ProductKeyword\n",
    "upload_df = ProductKeyword().update_product_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3rd) Update Vertical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.vertical_data import VerticalData\n",
    "VerticalData().update_vertical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4th) Update Best & New & Vegan & Organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.best_new import UpdateBestSellerNew\n",
    "from sephora_product.keywords import SephoraVeganOrganic\n",
    "UpdateBestSellerNew().update_best_new()\n",
    "SephoraVeganOrganic().update_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5th) Review Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.review_date import ReviewDate\n",
    "new_product_list, data = ReviewDate().update_review_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6th) Insert product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.insert_product_info import update_product_info\n",
    "result = update_product_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7th) All product update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_product.all_product_update import update_all_product\n",
    "data = update_all_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Search Keywords Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_keyword.search_keyword import update_search_keywords, db_distinction\n",
    "total_df = update_search_keywords()\n",
    "db_distinction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Review Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1st) Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backup table\n",
    "# table = 'sephora_txt_data_re'\n",
    "# db_glamai._backup(table_name=table, keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update review data\n",
    "from sephora_review.review_data import ReviewData\n",
    "txt_data, error = ReviewData()._crawling(backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['product_code', 'product_id', 'rating', 'skin_type', 'eye_color', 'skin_concerns', 'hair_color', 'skin_tone', 'age', 'title', 'txt_data', 'positive_count', 'write_time', 'regist_date']\n",
    "rev_df = pd.DataFrame(txt_data, columns=columns)\n",
    "\n",
    "error_df = pd.DataFrame(error, columns=['product_code', 'product_url', 'note'])\n",
    "error_df_cnt = error_df.groupby('note').count()\n",
    "\n",
    "rev_df.groupby('product_code').count()\n",
    "\n",
    "print(\\\n",
    "f\"product counts: {len(rev_df.product_code.unique())}\\n\\\n",
    "product review counts: {len(rev_df)}\\n\\\n",
    "reviews that already exist: {error_df_cnt.iloc[0, 0]}\\n\\\n",
    "review does not exist: {error_df_cnt.iloc[1, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2nd) Review Date Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sephora_review.review_data import ReviewDate\n",
    "result = ReviewDate().update_review_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3rd) Duplicate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/* replace */ \n",
    "UPDATE sephora_txt_data_re SET txt_data = REPLACE(txt_data, '.Not impressed.', '.') WHERE BINARY(txt_data) LIKE '%Not impressed.';\n",
    "\n",
    "/* check duplicated */\n",
    "select product_code, txt_data, write_time, like_count, count(*) as cnt\n",
    "from sephora_txt_data_re\n",
    "group by product_code, txt_data, write_time\n",
    "having cnt > 1;\n",
    "\n",
    "/* dedup */\n",
    "\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2 \n",
    "where \n",
    "t1.product_code=t2.product_code and \n",
    "t1.txt_data = t2.txt_data and \n",
    "t1.write_time =t2.write_time and\n",
    "t1.like_count < t2.like_count;\n",
    "\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2\n",
    "where \n",
    "t1.product_code = t2.product_code and \n",
    "t1.txt_data = t2.txt_data and\n",
    "t1.write_time = t2.write_time and\n",
    "t1.like_count = t2.like_count and\n",
    "t1.pk < t2.pk;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replace_query = \"UPDATE sephora_txt_data_re SET txt_data = REPLACE(txt_data, '.Not impressed.', '.') WHERE BINARY(txt_data) LIKE '%Not impressed.';\"\n",
    "dedup_query_1 = '''\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2 \n",
    "where \n",
    "t1.product_code=t2.product_code and \n",
    "t1.txt_data = t2.txt_data and \n",
    "t1.write_time =t2.write_time and\n",
    "t1.like_count < t2.like_count;\n",
    "'''\n",
    "dedup_query_2 = '''\n",
    "delete t1 \n",
    "from sephora_txt_data_re t1, sephora_txt_data_re t2\n",
    "where \n",
    "t1.product_code = t2.product_code and \n",
    "t1.txt_data = t2.txt_data and\n",
    "t1.write_time = t2.write_time and\n",
    "t1.like_count = t2.like_count and\n",
    "t1.pk < t2.pk;'''\n",
    "\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(replace_query)\n",
    "conn.commit()\n",
    "curs.execute(dedup_query_1)\n",
    "conn.commit()\n",
    "curs.execute(dedup_query_2)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dedup!\n"
     ]
    }
   ],
   "source": [
    "# Check query\n",
    "\n",
    "query = '''\n",
    "select product_code, txt_data, write_time, like_count, count(*) as cnt\n",
    "from sephora_txt_data_re\n",
    "group by product_code, txt_data, write_time\n",
    "having cnt > 1;'''\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "if len(data) == 0:\n",
    "    print('Complete dedup!')\n",
    "else:\n",
    "    print('Dedup Failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Status \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`face_base_product_info` Import Time: 0.3sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11803/11803 [1:53:25<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`sephora_face_base_data_status` is backuped successful!\n",
      "backup_table_name: sephora_face_base_data_status_bak_220928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [1:53:28<24:35:04, 6808.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Table Upload Success: `sephora_face_base_data_status`\n",
      "\n",
      "\n",
      "`eye_product_info` Import Time: 0.2sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6456/6456 [55:14<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`sephora_eye_data_status` is backuped successful!\n",
      "backup_table_name: sephora_eye_data_status_bak_220928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [2:48:44<15:50:48, 4754.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Table Upload Success: `sephora_eye_data_status`\n",
      "\n",
      "\n",
      "`lip_color_product_info` Import Time: 0.2sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4362/7121 [4:42:48<2:58:52,  3.89s/it]\n",
      " 14%|█▍        | 2/14 [7:31:33<45:09:20, 13546.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m verticals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_base\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meye\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlip_color\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoisturizers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheek\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meye_care\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_care\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmens\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfragrance_men\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfragrance_women\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwellness\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleansers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vertical \u001b[38;5;129;01min\u001b[39;00m tqdm(verticals):\n\u001b[0;32m----> 6\u001b[0m     status_data_df \u001b[38;5;241m=\u001b[39m update_sephora_status(vertical)\n\u001b[1;32m      7\u001b[0m     status_data_dict[vertical] \u001b[38;5;241m=\u001b[39m status_data_df\n",
      "File \u001b[0;32m~/Desktop/glamai/src/sephora_update/status.py:99\u001b[0m, in \u001b[0;36mupdate_sephora_status\u001b[0;34m(vertical)\u001b[0m\n\u001b[1;32m     97\u001b[0m price_org \u001b[39m=\u001b[39m info[\u001b[39m3\u001b[39m]\n\u001b[1;32m     98\u001b[0m regist_date \u001b[39m=\u001b[39m info[\u001b[39m4\u001b[39m]\n\u001b[0;32m---> 99\u001b[0m price, is_use \u001b[39m=\u001b[39m get_status(url, item_no)\n\u001b[1;32m    100\u001b[0m update_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mtoday()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m price \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/glamai/src/sephora_update/status.py:33\u001b[0m, in \u001b[0;36mget_status\u001b[0;34m(url, item_no)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_status\u001b[39m(url, item_no):\n\u001b[1;32m     32\u001b[0m     item_no \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(item_no)\n\u001b[0;32m---> 33\u001b[0m     request_data \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mget_headers())\n\u001b[1;32m     34\u001b[0m     request_text \u001b[39m=\u001b[39m request_data\u001b[39m.\u001b[39mtext\n\u001b[1;32m     35\u001b[0m     is_use \u001b[39m=\u001b[39m request_text\u001b[39m.\u001b[39mfind(item_no)\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/glamai/venv_glamai/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sephora_update.status import update_sephora_status\n",
    "\n",
    "status_data_dict = {}\n",
    "verticals = ['face_base', 'eye', 'lip_color', 'moisturizers', 'cheek', 'treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers']\n",
    "for vertical in tqdm(verticals):\n",
    "    status_data_df = update_sephora_status(vertical)\n",
    "    status_data_dict[vertical] = status_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sephora Product Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`sephora_cheek_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_cheek_data_sale_bak_220929\n",
      "cheek new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [02:25<00:00,  1.48it/s]\n",
      " 10%|█         | 1/10 [02:27<22:04, 147.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheek product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_treatments_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_treatments_data_sale_bak_220929\n",
      "treatments new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [05:25<00:00,  1.58it/s]\n",
      " 20%|██        | 2/10 [07:53<33:39, 252.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatments product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_masks_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_masks_data_sale_bak_220929\n",
      "masks new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [01:44<00:00,  1.59it/s]\n",
      " 30%|███       | 3/10 [09:38<21:37, 185.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_eye_care_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_eye_care_data_sale_bak_220929\n",
      "eye_care new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [01:50<00:00,  1.66it/s]\n",
      " 40%|████      | 4/10 [11:30<15:37, 156.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye_care product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_body_care_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_body_care_data_sale_bak_220929\n",
      "body_care new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:28<00:00,  1.66it/s]\n",
      " 50%|█████     | 5/10 [11:59<09:12, 110.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_care product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_mens_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_mens_data_sale_bak_220929\n",
      "mens new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:07<00:00,  1.54it/s]\n",
      " 60%|██████    | 6/10 [12:07<05:02, 75.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mens product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_fragrance_men_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_fragrance_men_data_sale_bak_220929\n",
      "fragrance_men new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [02:44<00:00,  1.54it/s]\n",
      " 70%|███████   | 7/10 [14:53<05:15, 105.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragrance_men product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_fragrance_women_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_fragrance_women_data_sale_bak_220929\n",
      "fragrance_women new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 693/693 [07:15<00:00,  1.59it/s]\n",
      " 80%|████████  | 8/10 [22:10<07:01, 210.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragrance_women product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_wellness_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_wellness_data_sale_bak_220929\n",
      "wellness new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:16<00:00,  1.63it/s]\n",
      " 90%|█████████ | 9/10 [23:27<02:49, 169.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wellness product sale status update 완료!\n",
      "\n",
      "\n",
      "`sephora_cleansers_data_sale` is backuped successful!\n",
      "backup_table_name: sephora_cleansers_data_sale_bak_220929\n",
      "cleansers new product update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [04:00<00:00,  1.65it/s]\n",
      "100%|██████████| 10/10 [27:29<00:00, 164.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleansers product sale status update 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sephora_update.sales import update_sephora_sale\n",
    "\n",
    "price_data_dict = {}\n",
    "# verticals = ['face_base', 'eye', 'lip_color', 'moisturizers', 'cheek', 'treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers']\n",
    "verticals = ['cheek', 'treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers']\n",
    "for vertical in tqdm(verticals):\n",
    "    price_data = update_sephora_sale(vertical)\n",
    "    price_data_dict[vertical] = price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verticals = ['face_base', 'eye', 'lip_color', 'moisturizers', 'cheek', 'treatments', 'masks', 'eye_care', 'body_care', 'mens', 'fragrance_men', 'fragrance_women', 'wellness', 'cleansers']\n",
    "\n",
    "# def update_sephora_sale_v(vertical):\n",
    "#     # backup table\n",
    "#     table_name = f'sephora_{vertical}_data_sale'\n",
    "#     db_glamai._backup(table_name=table_name, keep=True)\n",
    "    \n",
    "#     from sephora_update.sales import UpdateProductSale\n",
    "#     sale = UpdateProductSale()\n",
    "    \n",
    "#     sale.__conn__()\n",
    "#     product_codes = sale.get_data(vertical)\n",
    "#     sale.insert_data_new(vertical)\n",
    "\n",
    "#     status_info, price_datas = [], []\n",
    "#     for product_code in tqdm(product_codes):\n",
    "#         price_data, status = sale.update_data(product_code, vertical)\n",
    "        \n",
    "#         status_info.append([product_code, status])\n",
    "#         price_datas += price_data\n",
    "#     sale.__close__()\n",
    "#     print(f'{vertical} product status update 완료!')\n",
    "\n",
    "#     return price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Affiliate price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Amazon update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affiliate.amazon import get_data, _crawling, _upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = get_data()\n",
    "datas, error = [], []\n",
    "for value in tqdm(df_amazon.values):\n",
    "    data = _crawling(value)\n",
    "    if data is None:\n",
    "        affiliate_url = value[3]\n",
    "        error.append(affiliate_url)\n",
    "    else:\n",
    "        datas.append(data)\n",
    "crawling_df, upload_df = _upload(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_df = pd.read_csv('/Users/yeonseosla/Downloads/amazon_data.csv')\n",
    "upload_df = db_jangho.get_tbl('')\n",
    "upload_df.groupby('is_use').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df[upload_df.is_use==1].groupby('is_sale').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _upload_df = upload_df.copy()\n",
    "\n",
    "# _upload_df.loc[_upload_df.price < _upload_df.sale_price, 'price'] = _upload_df.loc[_upload_df.price < _upload_df.sale_price, 'sale_price']\n",
    "# _upload_df.loc[(_upload_df.price==_upload_df.sale_price) & (_upload_df.price!=0), ['is_sale', 'is_use']] = [0, 1]\n",
    "# _upload_df.loc[_upload_df.is_use==-1, ['is_sale', 'is_use']] = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _upload_df.groupby('is_use').count()\n",
    "# _upload_df[_upload_df.is_use==1].groupby('is_sale').count()\n",
    "# _upload_df.loc[(_upload_df.is_use==1)& (_upload_df.is_sale==0) & (_upload_df.sale_price==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_jangho.create_table(upload_df=_upload_df, table_name='affiliate_price_update_amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sale_price == price\n",
    "\n",
    "# today = '220914'\n",
    "# # today = db_jangho.today\n",
    "# query = f'''\n",
    "# update jangho.affiliate_price_update_amazon_{today} as a\n",
    "# join jangho.affiliate_price_update_amazon_{today} as b\n",
    "# on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "# set a.sale_price = b.price\n",
    "# where a.is_sale = 0 and a.is_use = 1 and a.sale_price = 0;'''\n",
    "\n",
    "# conn, curs = db_jangho._connect()\n",
    "# curs.execute(query)\n",
    "# conn.commit()\n",
    "# curs.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # is_use = 1\n",
    "\n",
    "# today = '220914'\n",
    "# # today = db_jangho.today\n",
    "# query = f'''\n",
    "# update affiliate_price_update_amazon_{today}\n",
    "# set is_use = 1\n",
    "# where is_use = 0 and price != 0;'''\n",
    "\n",
    "# conn, curs = db_jangho._connect()\n",
    "# curs.execute(query)\n",
    "# conn.commit()\n",
    "# curs.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = db_jangho.today\n",
    "today = '221006'\n",
    "query = f'''\n",
    "update glamai.affiliate_price as a\n",
    "join jangho.affiliate_price_update_amazon_{today} as b \n",
    "on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "set a.price = b.price, a.sale_price = b.sale_price, a.is_sale = b.is_sale, a.is_use = b.is_use, a.regist_date = b.regist_date, a.update_date = b.update_date;'''\n",
    "\n",
    "conn, curs = db_jangho._connect()\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Check query\n",
    "\n",
    "query = 'select * from affiliate_price where is_use=1 and is_sale=0 and sale_price=0;'\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "print(data)\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Ulta update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affiliate.ulta import get_data, _crawling, _upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ulta = get_data()\n",
    "datas, error = [], []\n",
    "for value in tqdm(df_ulta.values):\n",
    "    data = _crawling(value)\n",
    "    if data is None:\n",
    "        affiliate_url = value[3]\n",
    "        error.append(affiliate_url)\n",
    "    else:\n",
    "        datas.append(data)\n",
    "crawling_df, upload_df = _upload(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_jangho.create_table(upload_df=upload_df, table_name='affiliate_price_update_ulta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = '220913'\n",
    "# # today = db_jangho.today\n",
    "# query = f'''\n",
    "# update jangho.affiliate_price_update_ulta_{today} as a\n",
    "# join jangho.affiliate_price_update_ulta_{today} as b\n",
    "# on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "# set a.sale_price = b.price\n",
    "# where a.is_sale = 0 and a.is_use = 1 and a.sale_price = 0;'''\n",
    "\n",
    "# conn, curs = db_jangho._connect()\n",
    "# curs.execute(query)\n",
    "# conn.commit()\n",
    "# curs.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = '220913'\n",
    "# # today = db_jangho.today\n",
    "# query = f'''\n",
    "# update affiliate_price_update_ulta_{today}\n",
    "# set is_use = 1\n",
    "# where is_use = 0 and price != 0;'''\n",
    "\n",
    "# conn, curs = db_jangho._connect()\n",
    "# curs.execute(query)\n",
    "# conn.commit()\n",
    "# curs.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = db_jangho.today\n",
    "today = '221006'\n",
    "query = f'''\n",
    "update glamai.affiliate_price as a\n",
    "join jangho.affiliate_price_update_ulta_{today} as b \n",
    "on a.product_code = b.product_code and a.item_no = b.item_no and a.affiliate_type = b.affiliate_type\n",
    "set a.price = b.price, a.sale_price = b.sale_price, a.is_sale = b.is_sale, a.is_use = b.is_use, a.regist_date = b.regist_date, a.update_date = b.update_date;'''\n",
    "\n",
    "conn, curs = db_jangho._connect()\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "curs.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Check query\n",
    "\n",
    "query = 'select * from affiliate_price where is_use=1 and is_sale=0 and sale_price=0;'\n",
    "conn, curs = db_glamai._connect()\n",
    "curs.execute(query)\n",
    "data = curs.fetchall()\n",
    "print(data)\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Table Upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glamai_youtube_urls\n",
    "_date = '220926'\n",
    "df = pd.read_csv(f'/Users/yeonseosla/Downloads/glamai_youtube_total_{_date}_final.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_url = 'https://www.youtube.com/watch?v=3vpMAqQIs00'\n",
    "shorts = 'https://www.youtube.com/shorts/tvY8dOnO82s'\n",
    "\n",
    "df_ = df.copy()\n",
    "df_.loc[df_.yt_url.str[:9]=='/watch?v=', 'yt_id'] = df_.yt_url.str[9:]\n",
    "df_.loc[df_.yt_url.str[:9]!='/watch?v=', 'yt_id'] = df_.yt_url.str[8:]\n",
    "df_.loc[:, 'yt_url'] = 'https://www.youtube.com' + df_.loc[:, 'yt_url']\n",
    "df_.loc[df_.yt_url.str.contains('shorts'), 'duration'] = 'SHORTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24342 entries, 0 to 24341\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   product_code  24342 non-null  object\n",
      " 1   thumbnail     24342 non-null  object\n",
      " 2   title         24342 non-null  object\n",
      " 3   yt_url        24342 non-null  object\n",
      " 4   duration      6523 non-null   object\n",
      " 5   youtuber      24342 non-null  object\n",
      " 6   yt_id         24342 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`glamai_youtube_urls` Import Time: 2.8sec\n"
     ]
    }
   ],
   "source": [
    "glamai_youtube_urls = db_glamai.get_tbl('glamai_youtube_urls').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yt_id \n",
    "glamai_youtube_urls.loc[glamai_youtube_urls.yt_url.str.contains('watch'), 'yt_id'] = glamai_youtube_urls.yt_url.str[32:]\n",
    "glamai_youtube_urls.loc[glamai_youtube_urls.yt_url.str.contains('shorts'), 'yt_id'] = glamai_youtube_urls.yt_url.str[31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['product_code', 'thumbnail', 'title', 'yt_id', 'duration', 'youtuber']\n",
    "by = subset + ['regist_date']\n",
    "df_.loc[:, 'regist_date'] = datetime.now()\n",
    "df_concat = pd.concat([glamai_youtube_urls, df_])\n",
    "df_sorted = df_concat.sort_values(by=by, ascending=False)\n",
    "df_dedup = df_sorted.drop_duplicates(subset=subset, keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "`glamai_youtube_urls` is backuped successful!\n",
      "backup_table_name: glamai_youtube_urls_bak_220929\n",
      "\n",
      "\n",
      "Table Upload Success: `glamai_youtube_urls`\n"
     ]
    }
   ],
   "source": [
    "db_glamai.create_table(df_dedup, 'glamai_youtube_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv_glamai': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97a91e663fd71f51eb06874656961ba197eb8ffa793f4460cec412d5b186684e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
